[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "INLA and Log Gaussian Cox Processes: Theory and Application",
    "section": "",
    "text": "Preface\nThis is the blog post regarding Log-Gaussian Cox Processes.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a blog post about Log-Gaussian Cox Processes (LGCP). It is a follow up to the earlier blog post I made about Poisson Point Process models. In fact, the LGCP is an extension of the Poisson Point Process, in that a latent correlation structure is included in the point process model. Specifically, the LGCP uses a Gaussian Random Field to characterize the intensity of the point process. Doing so allows us to take into account spatial or temporal correlation across our region or period of interest.\nStatistically, this is quite an advantageous improvement from the Poisson Point Process where spatial correlation could only be accounted for via covariates. However, the inclusion of the random field presents mathematical and computational challenges. We will address these challenges here, making use of the Integrated Nested Laplace Approximation (INLA) approach.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "theory.html",
    "href": "theory.html",
    "title": "2  LGCP theory",
    "section": "",
    "text": "2.1 INLA\nA Poisson point process is a stochastic set of random variables in 2D space. The LGCP extends the process by incorporating spatial and potentially temporal correlation into the model. (diggle-2013?) is a good reference for these type of models. I’ll give some details below, and once the required mathematical details are presented, I will discuss the INLA approach for actually estimating the model.\nIn the Poisson Point Process the intensity is parameterized as \\[\n\\lambda(s) = \\theta(s)b(s) = \\exp[\\alpha + \\beta'x(s) + \\gamma + \\delta'z(s)]\n\\] In the LGCP we now incorporate a Gaussian Random Field (also described as Gaussian spatial field, spatial random effects, or latent spatial field) to incorporate spatial correlation between sites \\[\n\\lambda(s) = \\theta(s)b(s) = \\exp[\\alpha + \\beta'x(s) + \\gamma + \\delta'z(s) + w(s)]\n\\] The Gaussian Random field \\(w(s)\\) can be thought of as a continuous spatial effect that is evaluated at certain locations. random effect. With this parameterization, the expected value for quadrat \\(A\\) will be the integral over the quadrat: \\[\n\\Delta(A) = \\int_A\\lambda(s)ds = \\int_A \\exp[\\alpha + \\beta'x(s) + \\gamma + \\delta'z(s) + w(s)]ds\n\\] However, this forces us to use a covariance structure that grows in size as the area of interest or the number of observations increase in area. Thus, the computational complexity makes this approach prohibitively costly for large regions when using MCMC approaches to estimate this model.\nIntegrated Nested Laplace Approximations have been proposed by (rue-2009?) as a fast way to estimate models with latent Gaussian structure. From the paper, we are concerned with models with an additive predictor that takes the general form \\[\n\\eta_i = \\alpha + \\sum^{n_f}_{j=1}f^{(j)}(u_{ij}) + \\sum^{n_{\\beta}}_{k=1} \\beta_kz_{ki} + \\epsilon_i\n\\] where \\(\\alpha\\) is an intercept, \\(f\\) are unknown functions of \\(u\\), and \\(\\beta\\) are the typical fixed effects effect for covariates \\(z\\).\nThe joint posterior is written as \\[\n\\begin{aligned}\n\\pi(x,\\theta|y)\\propto\\pi(\\theta)\\pi(x|\\theta)\\prod_{i\\in I}\\pi(y_i|x_i,\\theta)\\\\\n\\propto\\pi(\\theta)|Q(\\theta)|^{1/2}\\exp\\bigg[\\frac{1}{2}x^TQ(\\theta)x+\\sum_{i\\in I}\\log\\{\\pi(y_i|x_i,\\theta)\\}\\bigg],\n\\end{aligned}\n\\]\nThe main point of INLA is to make the nested approximations of the hyperparameters \\[\np(\\theta_j|y) = \\int p(\\theta|y)d\\theta_{j}\n\\]\nand the latent field \\[\n\\tilde{\\pi}(x_i|y) = \\int \\tilde{\\pi}(x_i|\\theta,y)\\tilde{\\pi}(\\theta|y)d\\theta,\n\\]\nTODO: Finish the notes from this, and just maybe making some details of it concrete in my head. Also, should this blog be LGCPs only or INLA in general? The LGCP thing isn’t that special really. So maybe make it INLA for spatial models, and have a part on genarlly continuous model and then do the tutorial, then do the LGCP model, then do combined likelihoods.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LGCP theory</span>"
    ]
  },
  {
    "objectID": "theory.html#spde-connection",
    "href": "theory.html#spde-connection",
    "title": "2  LGCP theory",
    "section": "2.2 SPDE connection",
    "text": "2.2 SPDE connection\nThe SPDE approach represents the continuous Gaussian Field with a discretely indexed Gaussian Markov Random Field, using a basis function defined on a triangulation of the region of interest.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LGCP theory</span>"
    ]
  },
  {
    "objectID": "theory.html#covariance-matrices",
    "href": "theory.html#covariance-matrices",
    "title": "2  LGCP theory",
    "section": "2.3 Covariance Matrices",
    "text": "2.3 Covariance Matrices\nThe matern covariance \\[\nr(u,v) = \\frac{\\sigma^2}{2^{\\nu-1}\\Gamma(\\nu)}(\\kappa ||v-u||)^\\nu K_\\nu(\\kappa ||v-u||).\n\\]\nFrom https://www.youtube.com/watch?v=CCuWHaYxVFg&ab_channel=RConsortium: The precision matrix is sparse for Markovian process. Gaussian distributoins with sparse precision matrices are Guassian Markov Random Fields",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LGCP theory</span>"
    ]
  },
  {
    "objectID": "theory.html#mesh",
    "href": "theory.html#mesh",
    "title": "2  LGCP theory",
    "section": "2.4 Mesh",
    "text": "2.4 Mesh\nThe mesh is is used to project the discrete GRMF to the continuous GF using some spatial weights defined at the vertices of the mesh (did I say that right?). From the Moraga tutorial above, she says the continuous process is estimated using a weighted average of the process at the vertices of the discrete triangulation mesh.\nThe projection matrix maps the GMRF from the observations to the triangulation nodes. The observation will be the weighted average using the weights and values from the triangulation and projection matrix. \\[\nS(x_i) \\approx \\sum^G_{g=1}A_{ig}S_g\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LGCP theory</span>"
    ]
  },
  {
    "objectID": "theory.html#simpson-2016",
    "href": "theory.html#simpson-2016",
    "title": "2  LGCP theory",
    "section": "2.5 Simpson 2016",
    "text": "2.5 Simpson 2016",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LGCP theory</span>"
    ]
  },
  {
    "objectID": "approximation.html",
    "href": "approximation.html",
    "title": "3  Approximation",
    "section": "",
    "text": "3.1 Laplace’s approximation.\nSome of this writing and notation is liberally taken from E.T. Krainski et al. (2019). I highly appreciate the work they did by providing a clearly communicated and freely available resource explaining the INLA + SPDE approach and its application.\nThe Laplace approximation is used to approximate the marginal distribution of a latent function \\(f(x)\\) taken from a joint posterior.\nInclude some derivation here based on Gaussian process?? See Vanhtalo 2010, Rue 2009, Lindgren 2011, Bolin 2011, Cameletti 2013, Simpson 2016.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Approximation</span>"
    ]
  },
  {
    "objectID": "approximation.html#inla",
    "href": "approximation.html#inla",
    "title": "3  Approximation",
    "section": "3.2 INLA",
    "text": "3.2 INLA\nINLA is a numerical approximation based on (rue2009?).\nFor software: Illian 2013, Rue 2013b, Lindgren 2015.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Approximation</span>"
    ]
  },
  {
    "objectID": "approximation.html#spde",
    "href": "approximation.html#spde",
    "title": "3  Approximation",
    "section": "3.3 SPDE",
    "text": "3.3 SPDE\nCameletti (2013) has a implementation of SPDE and does a nice job describing the theory in an introductory but not basic way.\nThe innovation of the SPDE approach is to develop a GRMF that represents the matern covariance structure, so that inference inherits the faster computational properties of the GFMF and does not suffer the computational cost due to increasing the size of the spatial region and thus the covariance matrix computations.\nLindgren 2011 find that a GF with matern covariance structure is a solution to a SPDE. The GRMF representation allows the use of a sparese matrix represesntation of the covariance structure.\nThey additionally provide a triangulation of the spatial region for approximation of the process likelihood. Basically, just approximate the density of the spatial process with triangulation in space using a set of basis functions\n\\[\nu(s) = \\sum^m_{k=1}\\psi_k(s)w_k\n\\] with \\(\\psi_k(s)\\) basis functions and gaussian weights \\(w_k\\).\nThis approach can be implemented in the INLA framework.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Approximation</span>"
    ]
  },
  {
    "objectID": "approximation.html#mesh",
    "href": "approximation.html#mesh",
    "title": "3  Approximation",
    "section": "3.4 Mesh",
    "text": "3.4 Mesh\nFinally, (Simpson2016?) improved upon the representation of the GRMF using a dual mush across the region.\nFrom the book by E.T. Krainski et al. (2019): ” They develop this solution by considering basis functions carefully chosen to preserve the sparse structure of the resulting precision matrix for the random field at a set of mesh nodes. This provides an explicit link between a continuous random field and a GMRF representation, which allows efficient computations.”",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Approximation</span>"
    ]
  }
]