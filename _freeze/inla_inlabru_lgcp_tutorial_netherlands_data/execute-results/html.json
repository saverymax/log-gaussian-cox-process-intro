{
  "hash": "820292879bfb4ceddd6e2884be3cf774",
  "result": {
    "markdown": "# Implementation of LGCP in INLA and INLABRU\n\n## LGCP in INLA \n\nHaving completed air pollution modelling in `INLA` and `inlabru`, it is time to move on to the LGCP and the point process model. A couple of resources about point process modelling in INLA include: <https://becarioprecario.bitbucket.io/spde-gitbook/ch-stapp.html#sec:burkitt> and <https://www.paulamoraga.com/book-spatial/point-process-modeling.html>. I'll again be relying on the Moraga book for template code.\n\nThe model fit here has intensity specified as \n$$\n\\lambda(s) = \\beta_0 + f(s)\n$$\nHere I only use an intercept and spatial field to model the intensity, so we won't have to worry about downloading any covariates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(INLA)\nlibrary(inlabru)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(viridis)\nlibrary(terra)\nlibrary(dplyr)\nlibrary(readr)\n```\n:::\n\nNow for the data. I'll use butterfly data from citizen science observations made in the Netherlands in 2023. The data is available in the GBIF repository <https://doi.org/10.15468/dl.p5cy6n>, which includes all butterfly observations uploaded to observation.org. So it's necessary to filter the dataset down to just the Netherlands. I filter for the species Lasiommata megera. This leaves us with 2705 observations.\n\n::: {.cell}\n\n```{.r .cell-code}\nfile_name <- file.path(\"D:\", \"data\", \"gbif_observation_org_butterflies\", \"gbif_butterfly_observation-org\", \"gbif_subset_netherlands_lepidoptera.csv\")\nd <- read_delim(file_name, delim='\\t', col_types=cols(infraspecificEpithet=col_character()))\nd %>% filter(species==\"Lasiommata megera\") -> d\ndim(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2705   50\n```\n:::\n\n```{.r .cell-code}\nsum(is.na(d))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 45001\n```\n:::\n\n```{.r .cell-code}\nd <- st_as_sf(d, coords = c(\"decimalLongitude\", \"decimalLatitude\"))\nst_crs(d) <- \"EPSG:4326\"\nst_crs(\"EPSG:3857\")$proj4string\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"+proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +k=1 +units=m +nadgrids=@null +wktext +no_defs\"\n```\n:::\n\n```{.r .cell-code}\nprojMercator <- \"+proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0\n+x_0=0 +y_0=0 +k=1 +units=km +nadgrids=@null +wktext +no_defs\"\n# Observed coordinates\nd <- st_transform(d, crs = projMercator)\n```\n:::\n\nBefore, I used the Netherlands map directly, but now there is some extra processing to do, due to little isolated boundaries within the main polygon of the Netherlands border.\n\n::: {.cell}\n\n```{.r .cell-code}\n?st_layers\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nstarting httpd help server ... done\n```\n:::\n\n```{.r .cell-code}\nlayers <- st_layers(file.path(\"D:\", \"data\", \"maps\", \"netherlands_bestuurlijkegrenzen_2021\", \"bestuurlijkegrenzen.gpkg\"))\n#print(str(layers))\nmap <- st_read(file.path(\"D:\", \"data\", \"maps\", \"netherlands_bestuurlijkegrenzen_2021\", \"bestuurlijkegrenzen.gpkg\"), layer = \"landsgrens\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `landsgrens' from data source \n  `D:\\data\\maps\\netherlands_bestuurlijkegrenzen_2021\\bestuurlijkegrenzen.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1 feature and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 10425.16 ymin: 306846.2 xmax: 278026.1 ymax: 621876.3\nProjected CRS: Amersfoort / RD New\n```\n:::\n\n```{.r .cell-code}\nmap <- st_union(map)\nmap <- st_as_sf(map)\n# there's a little isolated spec in the map!\nborder_polygon <- st_cast(map, \"POLYGON\")\nborder_polygon <- st_as_sfc(border_polygon)\ngeos <- lapply(border_polygon, function(x) x[1])\n#for (g in geos){\n#  plot(st_polygon(g))\n#}\n# Get the border polygon\nborder_final <- st_polygon(geos[[1]])\n# We still need sf object\nborder_final <- st_sfc(border_final, crs=st_crs(map))\nborder_final <- st_as_sf(border_final)\nplot(border_final)\n```\n\n::: {.cell-output-display}\n![](inla_inlabru_lgcp_tutorial_netherlands_data_files/figure-html/map-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmap <- border_final\nmap <- st_transform(map, crs = projMercator)\ncoo <- st_coordinates(d)\nggplot() + geom_sf(data = map) +\n  geom_sf(data = d) + coord_sf(datum = projMercator)\n```\n\n::: {.cell-output-display}\n![](inla_inlabru_lgcp_tutorial_netherlands_data_files/figure-html/map-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Save this for later\nst_write(map, file.path(\"D:\", \"data\", \"maps\", \"netherlands_bestuurlijkegrenzen_2021\", \"clean_nl_boundary.gpkg\"), append=F)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDeleting layer `clean_nl_boundary' using driver `GPKG'\nWriting layer `clean_nl_boundary' to data source \n  `D:/data/maps/netherlands_bestuurlijkegrenzen_2021/clean_nl_boundary.gpkg' using driver `GPKG'\nWriting 1 features with 0 fields and geometry type Polygon.\n```\n:::\n:::\n\nSo that gives us a very clean map, with the location of Lasiommata megera observations.\n\nAs in the previos example for air pollution data, we again create prediction points across the spatial region. These will be the locations at which the intensity is predicted.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# raster grid covering map\ngrid <- terra::rast(map, nrows = 50, ncols = 50)\n# coordinates of all cells\nxy <- terra::xyFromCell(grid, 1:ncell(grid))\n# transform points to a sf object\ndp <- st_as_sf(as.data.frame(xy), coords = c(\"x\", \"y\"),\n               crs = st_crs(map))\n\n# indices points within the map\nindicespointswithin <- which(st_intersects(dp, map,\n                                           sparse = FALSE))\n\n# points within the map\ndp <- st_filter(dp, map)\n\nggplot() + geom_sf(data = map) +\n  geom_sf(data = dp) + coord_sf(datum = projMercator)\n```\n\n::: {.cell-output-display}\n![](inla_inlabru_lgcp_tutorial_netherlands_data_files/figure-html/prediction-locations-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncoop <- st_coordinates(dp)\n```\n:::\n\nNext, build the mesh. \n\n::: {.cell}\n\n```{.r .cell-code}\nloc.d <- cbind(st_coordinates(map)[, 1], st_coordinates(map)[, 2])\n#mesh <- inla.mesh.2d(loc=coo, max.edge = c(50000, 100000))\n#mesh <- inla.mesh.2d(loc.domain=loc.d)\nmesh <- inla.mesh.2d(loc.domain = loc.d, max.edge = c(50, 100), crs=crs(d))\nplot(mesh)\npoints(coo, col = \"red\")\naxis(1)\naxis(2)\n```\n\n::: {.cell-output-display}\n![](inla_inlabru_lgcp_tutorial_netherlands_data_files/figure-html/mesh-1.png){width=672}\n:::\n\n```{.r .cell-code}\n(nv <- mesh$n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 324\n```\n:::\n\n```{.r .cell-code}\n(n <- nrow(coo))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2705\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nspde <- inla.spde2.matern(mesh = mesh, alpha = 2, constr = TRUE)\n```\n:::\n\nIn the point process setting, it is necessary to use the method of @simpson2016. This uses a dual mesh to approximate the point process likelihood. It is called a dual mesh because a mesh of polygons is generated, each centered around the vertices of the triangles in the first mesh. The code to create the dual mesh is available in both the SPDE book and Moraga book.\n\n::: {.cell}\n\n```{.r .cell-code}\nbook.mesh.dual <- function(mesh) {\n    if (mesh$manifold=='R2') {\n        ce <- t(sapply(1:nrow(mesh$graph$tv), function(i)\n            colMeans(mesh$loc[mesh$graph$tv[i, ], 1:2])))\n        library(parallel)\n        pls <- mclapply(1:mesh$n, function(i) {\n            p <- unique(Reduce('rbind', lapply(1:3, function(k) {\n            j <- which(mesh$graph$tv[,k]==i)\n            if (length(j)>0) \n            return(rbind(ce[j, , drop=FALSE],\n            cbind(mesh$loc[mesh$graph$tv[j, k], 1] +\n            mesh$loc[mesh$graph$tv[j, c(2:3,1)[k]], 1], \n            mesh$loc[mesh$graph$tv[j, k], 2] +\n            mesh$loc[mesh$graph$tv[j, c(2:3,1)[k]], 2])/2))\n            else return(ce[j, , drop=FALSE])\n            })))\n            j1 <- which(mesh$segm$bnd$idx[,1]==i)\n            j2 <- which(mesh$segm$bnd$idx[,2]==i)\n            if ((length(j1)>0) | (length(j2)>0)) {\n            p <- unique(rbind(mesh$loc[i, 1:2], p,\n            mesh$loc[mesh$segm$bnd$idx[j1, 1], 1:2]/2 +\n            mesh$loc[mesh$segm$bnd$idx[j1, 2], 1:2]/2, \n            mesh$loc[mesh$segm$bnd$idx[j2, 1], 1:2]/2 +\n            mesh$loc[mesh$segm$bnd$idx[j2, 2], 1:2]/2))\n            yy <- p[,2]-mean(p[,2])/2-mesh$loc[i, 2]/2\n            xx <- p[,1]-mean(p[,1])/2-mesh$loc[i, 1]/2\n            }\n            else {\n            yy <- p[,2]-mesh$loc[i, 2]\n            xx <- p[,1]-mesh$loc[i, 1]\n            }\n            Polygon(p[order(atan2(yy,xx)), ])\n        })\n        return(SpatialPolygons(lapply(1:mesh$n, function(i)\n            Polygons(list(pls[[i]]), i))))\n    }\n    else stop(\"It only works for R2!\")\n}\ndmesh <- book.mesh.dual(mesh)\nplot(dmesh)\naxis(1)\naxis(2)\n```\n\n::: {.cell-output-display}\n![](inla_inlabru_lgcp_tutorial_netherlands_data_files/figure-html/dual-mesh-1.png){width=672}\n:::\n:::\n\nWe then do something a little tricky. The mesh is larger than the domain that the points were observed in or the study region. So the intersections between the polygons in the mesh and the locations in $D$ are computed. \n\n::: {.cell}\n\n```{.r .cell-code}\ndomain.polys <- Polygons(list(Polygon(loc.d)), '0')\ndomainSP <- SpatialPolygons(list(domain.polys))\ndomain_sf <- st_as_sf(domainSP)\ndomain_sf <- st_set_crs(domain_sf, projMercator)\nmesh_sf <- st_as_sf(dmesh)\nmesh_sf <- st_set_crs(mesh_sf, projMercator)\n# Check if the mesh polygons overlap with any of the locations \nw <- sapply(1:length(dmesh), function(i) {\n  if(length(st_intersects(mesh_sf[i,], domain_sf)[[1]])>0){\n    return(sf::st_area(sf::st_intersection(mesh_sf[i, ], domain_sf)))\n  }\n  else return(0)\n})\nsum(w)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 111060.6\n```\n:::\n\n```{.r .cell-code}\nst_area(map)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n111060.6 [km^2]\n```\n:::\n:::\n\nThat leaves us with a very nice looking mesh, where the black integration points fall within the Netherlands domain and red fall outside of it.\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mesh)\nplot(domain_sf, add=T, col=\"green\")\npoints(mesh$loc[which(w > 0), 1:2], col = \"black\", pch = 20)\npoints(mesh$loc[which(w == 0), 1:2], col = \"red\", pch = 20)\n```\n\n::: {.cell-output-display}\n![](inla_inlabru_lgcp_tutorial_netherlands_data_files/figure-html/plot-mesh-1.png){width=672}\n:::\n:::\n\nNext, create the `INLA` stack, for both observations and for prediction points.\n\n::: {.cell}\n\n```{.r .cell-code}\ny.pp <- rep(0:1, c(nv, n))\ne.pp <- c(w, rep(0, n))\n# Projection matrix for the integration points (mesh vertices)\nA.int <- Diagonal(nv, rep(1, nv))\n# Projection matrix for observed points (event locations)\nA.y <- inla.spde.make.A(mesh = mesh, loc = coo)\n# Projection matrix for mesh vertices and event locations\nA.pp <- rbind(A.int, A.y)\n\n# We also create the projection matrix Ap.pp for the prediction locations.\nAp.pp <- inla.spde.make.A(mesh = mesh, loc = coop)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# stack for estimation\nstk.e.pp <- inla.stack(tag = \"est.pp\",\ndata = list(y = y.pp, e = e.pp), \nA = list(1, A.pp),\neffects = list(list(b0 = rep(1, nv + n)), list(s = 1:nv)))\n\n# stack for prediction stk.p\nstk.p.pp <- inla.stack(tag = \"pred.pp\",\ndata = list(y = rep(NA, nrow(coop)), e = rep(0, nrow(coop))),\nA = list(1, Ap.pp),\neffects = list(data.frame(b0 = rep(1, nrow(coop))),\n               list(s = 1:nv)))\n\n# stk.full has stk.e and stk.p\nstk.full.pp <- inla.stack(stk.e.pp, stk.p.pp)\n```\n:::\n\nFinally, we can fit the model. This looks about the same as in the continuous setting. Notice the different strategy options for both the integration strategy and for the posterior approximation itself. `control.predictor` returns the posterior marginals, with `link=1` using the same link function as given in `family = 'poisson'`.\n\n::: {.cell}\n\n```{.r .cell-code}\nformula <- y ~ 0 + b0 + f(s, model = spde)\nres <- inla(formula,  family = 'poisson',\n  data = inla.stack.data(stk.full.pp),\n  control.inla=list(int.strategy = 'grid', strategy=\"laplace\"),\n  control.predictor = list(compute = TRUE, link = 1,\n    A = inla.stack.A(stk.full.pp)),\n    E = inla.stack.data(stk.full.pp)$e)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nres$summary.fixed\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mean       sd 0.025quant 0.5quant 0.975quant     mode          kld\nb0 7.548762 1.247818   5.101914 7.548762   9.995609 7.548762 5.527137e-11\n```\n:::\n\n```{.r .cell-code}\nres$summary.hyperpar\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  mean          sd 0.025quant   0.5quant 0.975quant       mode\nTheta1 for s  0.705707 0.003661819  0.7006706  0.7051314  0.7143486  0.7025326\nTheta2 for s -5.268760 0.001979831 -5.2728767 -5.2686853 -5.2650983 -5.2683425\n```\n:::\n\n```{.r .cell-code}\nindex <- inla.stack.index(stk.full.pp, tag = \"pred.pp\")$data\npred_mean <- res$summary.fitted.values[index, \"mean\"]\npred_ll <- res$summary.fitted.values[index, \"0.025quant\"]\npred_ul <- res$summary.fitted.values[index, \"0.975quant\"]\ngrid$mean <- NA\ngrid$ll <- NA\ngrid$ul <- NA\n\ngrid$mean[indicespointswithin] <- pred_mean\ngrid$ll[indicespointswithin] <- pred_ll\ngrid$ul[indicespointswithin] <- pred_ul\n```\n:::\n\nWe can check the estimate for the intercept, as well as the parameters for the spatial field.\n\nThen plot the predicted intensity\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(grid)\ngeom_sf(data=grid, aes(color=mean)) +\n  scale_colour_gradient(low = \"blue\", high = \"yellow\")\n```\n:::\n\n\n\nWe have to make sure to get the domain for the sampler correct. The INLA code does it above, but inlabru by default does not.\n\nMore about that <https://inlabru-org.github.io/inlabru/articles/2d_lgcp_plotsampling.html>\nand actually the exact problem here: <https://groups.google.com/g/r-inla-discussion-group/c/0bBC9bVV-L4> even though the problem was with preferential sampling. In the mesh-process R section above, you can see the manipulation to get the domains correct for INLA. Even with including ```sampler=domain_sf``` here, the estimates are not exactly the same as INLA, but closer than it was before.\n\nTODO: What is this domain stuff for exactly? The integration? Should be equation 3 of Simpson (2016).\n\n::: {.cell}\n\n```{.r .cell-code}\n# TODO: Make sure I get the same result as inla. Options and mesh are off\n# Oh nice we can name the intercept but then need to subtract 1 to get rid of the default intercept\nformula_inlabru <- geometry ~ b0(1) - 1 + f(geometry, model = spde)\nfit1 <- lgcp(formula_inlabru, data=d, sampler=domain_sf, domain = list(geometry = mesh), \n             options = list(control.inla=list(int.strategy = 'ccd', strategy=\"laplace\")))\n#                          control.compute=list(config=TRUE),\n#                          control.results=list(return.marginals.random = TRUE,\n#                                               return.marginals.predictor = TRUE),\n#                          control.predictor = list(compute = TRUE)))\n\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ninlabru version: 2.12.0\nINLA version: 24.05.01-1\nComponents:\nb0: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL\nf: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL\nLikelihoods:\n  Family: 'cp'\n    Tag: ''\n    Data class: 'sf', 'data.frame'\n    Response class: 'numeric'\n    Predictor: geometry ~ .\n    Used components: effects[b0, f], latent[]\nTime used:\n    Pre = 0.733, Running = 35.4, Post = 0.107, Total = 36.2 \nFixed effects:\n   mean sd 0.025quant 0.5quant 0.975quant mode kld\nb0    0  0          0        0          0    0   0\n\nRandom effects:\n  Name\t  Model\n    f SPDE2 model\n\nModel hyperparameters:\n               mean    sd 0.025quant 0.5quant 0.975quant   mode\nTheta1 for f -16.85 0.001     -16.85   -16.85     -16.84 -16.84\nTheta2 for f -15.62 0.001     -15.62   -15.62     -15.61 -15.62\n\nDeviance Information Criterion (DIC) ...............: 2036967.57\nDeviance Information Criterion (DIC, saturated) ....: NA\nEffective number of parameters .....................: 2015416.99\n\nWatanabe-Akaike information criterion (WAIC) ...: -Inf\nEffective number of parameters .................: 17168.33\n\nMarginal log-Likelihood:  472331.69 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n```\n:::\n:::\n\n\nTODO: Oh wow, why is b0 so different between inla and inlabru.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions1 <- predict(fit1, newdata=dp, formula = ~ b0 + f)\npredictions2 <- predict(fit1, newdata=dp, formula = ~ f)\nggplot() +\ngeom_sf(data=predictions1, aes(color=mean)) +\n  scale_colour_gradient(low = \"blue\", high = \"yellow\")\n```\n\n::: {.cell-output-display}\n![](inla_inlabru_lgcp_tutorial_netherlands_data_files/figure-html/preds-intensity-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Check the contribution of just the spatial field\nggplot() +\ngeom_sf(data=predictions2, aes(color=mean)) +\n  scale_colour_gradient(low = \"blue\", high = \"yellow\")\n```\n\n::: {.cell-output-display}\n![](inla_inlabru_lgcp_tutorial_netherlands_data_files/figure-html/preds-intensity-2.png){width=672}\n:::\n:::\n\n\n\n\nThen, we can move onto multiple likelihoods and inlabru\n",
    "supporting": [
      "inla_inlabru_lgcp_tutorial_netherlands_data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}